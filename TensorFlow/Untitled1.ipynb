{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5696c63053a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# pylab.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# 数据下载\n",
    "#################\n",
    "# from tensorflow.examples.tutorials.mnist import  input_data\n",
    "# import pylab\n",
    "# mnist = input_data.read_data_sets(\"MINST_daya/\", one_hot=True)\n",
    "\n",
    "# print(\"输入数据：\",mnist.train.images)\n",
    "# print(\"数据的shape：\",mnist.train.images.shape)\n",
    "# # 展示数据集中的一张图片\n",
    "# im = mnist.train.images[1]\n",
    "# im = im.reshape(-1,28)\n",
    "# pylab.imshow(im)\n",
    "# pylab.show()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import  input_data\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "mnist = input_data.read_data_sets(\"MINST_daya/\", one_hot=True)\n",
    "tf.reset_default_graph()\n",
    "# 定义占位符\n",
    "x = tf.placeholder(tf.float32, [None, 784])  # mnist data 维度28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "# 定义学习参数\n",
    "# 设置模型的权重\n",
    "W = tf.Variable(tf.random_normal([784, 10]))  # W的维度是[784, 10]\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# 定义输出节点， 构建模型\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "# 定义反向传播的结构，编译训练模型，得到合适的参数\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# 参数设置/学习率\n",
    "learning_rate = 0.01\n",
    "# 使用梯度下降优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "startTime = datetime.now()\n",
    "#\n",
    "# original\n",
    "#\n",
    "# training_epochs = 25   # 将整个训练样本迭代25次\n",
    "# batch_size = 100    # 在训练过程中每次随机抽取100条数据进行训练\n",
    "# display_step = 1   # 迭代的步数\n",
    "# saver = tf.train.Saver()\n",
    "# model_path = \"mnist/521model.ckpt\"\n",
    "# me\n",
    "# training_epochs = 100   \n",
    "# batch_size = 100   \n",
    "# display_step = 1   \n",
    "# saver = tf.train.Saver()\n",
    "# model_path = \"mnist/521model.ckpt\"\n",
    "\n",
    "# print('==========初次训练============')\n",
    "# # 开始训练\n",
    "# with tf.Session()  as sess:\n",
    "#     # 初始化节点\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     # 启动循环开始训练\n",
    "#     for epoch in range(training_epochs):\n",
    "#         avg_cost = 0.\n",
    "#         total_batch = int(mnist.train.num_examples/batch_size)\n",
    "#         # 遍历全部的数据集\n",
    "#         for i in range(total_batch):\n",
    "#             batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "#             # 运行和优化节点的损失函数值\n",
    "#             _, c = sess.run([optimizer, cost], feed_dict={x:batch_xs,\n",
    "#                                                           y: batch_ys})\n",
    "#             # 计算平均损失值\n",
    "#             avg_cost += c / total_batch\n",
    "#         # 显示训练中的详细信息\n",
    "#         # if (epoch+1) % display_step ==0:\n",
    "#         #     print(\"Epoch:\",\"%04d\"%(epoch+1), \"cost=\",'{:.9f}'.format(avg_cost))\n",
    "#     print(\"训练成功！！\")\n",
    "#     # 模型测试\n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     # 计算准确率\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print(\"准确度：\",accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "#     # 保存模型的权重\n",
    "#     save_path = saver.save(sess, model_path)\n",
    "#     print(\"模型文件在：%s\"%save_path)\n",
    "\n",
    "# print(\"Time taken:\", datetime.now() - startTime)\n",
    "# # 该模块是第一次训练模块后的精准读来弄的\n",
    "# startTime = datetime.now()\n",
    "# # 读取模型\n",
    "# print(\"检验第一次训练的情况\")\n",
    "# with tf.Session() as sess2:\n",
    "#     # 初始化参数\n",
    "#     sess2.run(tf.global_variables_initializer())\n",
    "#     ############################\n",
    "#     #\n",
    "#     #从保存的模型中获取权重\n",
    "#     #\n",
    "#     ###########################\n",
    "#     saver.restore(sess2, model_path)\n",
    "#     # 测试 model\n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     # 计算准确率\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print(\"准确度：\",accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "#     output = tf.argmax(pred, 1)\n",
    "#     batch_xs, batch_ys = mnist.train.next_batch(2)\n",
    "#     outputval, predv = sess2.run([output, pred], feed_dict={x:batch_xs})\n",
    "#     print(outputval, pred, batch_ys)\n",
    "#     im = batch_xs[0]\n",
    "#     im = im.reshape(-1, 28)\n",
    "#     pylab.imshow(im)\n",
    "#     pylab.show()\n",
    "#     im = batch_xs[1]\n",
    "#     im = im.reshape(-1, 28)\n",
    "#     pylab.imshow(im)\n",
    "#     pylab.show()\n",
    "# print(\"Time taken:\", datetime.now() - startTime)\n",
    "# print()\n",
    "# print('******************************')\n",
    "# print()\n",
    "\n",
    "print('===============第二次训练================')\n",
    "###################\n",
    "# 测试是否能在原有的基础上来提高训练精度(目前是0.9212)\n",
    "##################\n",
    "training_epochs = 10000  \n",
    "batch_size = 100   \n",
    "display_step = 1   \n",
    "saver = tf.train.Saver()\n",
    "model_path = \"mnist/521model.ckpt\"\n",
    "startTime = datetime.now()\n",
    "# 读取模型\n",
    "print(\"启动第二次session\")\n",
    "# Creates a session with log_device_placement set to True.\n",
    "with tf.Session() as sess2:\n",
    "    # 初始化参数\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    #从保存的模型中获取权重\n",
    "    saver.restore(sess2, model_path)\n",
    "     # 启动循环开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 遍历全部的数据集\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行和优化节点的损失函数值\n",
    "            _, c = sess2.run([optimizer, cost], feed_dict={x:batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # 计算平均损失值\n",
    "            avg_cost += c / total_batch\n",
    "        # 显示训练中的详细信息\n",
    "        if (epoch+1) % display_step ==0:\n",
    "            print(\"Epoch:\",\"%04d\"%(epoch+1), \"cost=\",'{:.9f}'.format(avg_cost))\n",
    "            # 每次训练都保存一下当前的模型，以防崩溃产生的损失\n",
    "            save_path = saver.save(sess2, model_path)\n",
    "    print(\"训练成功！！\")\n",
    "    # 模型测试\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # 计算准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"准确度：\",accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "    # 保存模型的权重\n",
    "    # save_path = saver.save(sess2, model_path)\n",
    "    print(\"模型文件在：%s\"%save_path)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "# 读取模型\n",
    "print(\"测试第二次训练的情况\")\n",
    "with tf.Session() as sess3:\n",
    "    # 初始化参数\n",
    "    sess3.run(tf.global_variables_initializer())\n",
    "    #从保存的模型中获取权重\n",
    "    saver.restore(sess3, model_path)\n",
    "    # 测试 model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # 计算准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"准确度：\",accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "    \n",
    "    output = tf.argmax(pred, 1)\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(2)\n",
    "    outputval, predv = sess3.run([output, pred], feed_dict={x:batch_xs})\n",
    "    print(outputval, pred, batch_ys)\n",
    "\n",
    "    im = batch_xs[0]\n",
    "    im = im.reshape(-1, 28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "\n",
    "    im = batch_xs[1]\n",
    "    im = im.reshape(-1, 28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "\n",
    "print(\"Time taken:\", datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
